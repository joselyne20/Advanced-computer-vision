{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joselyne20/Advanced-computer-vision/blob/main/tutorial_1b_mnist1d_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial 1b: MNIST-1D Classification**\n",
        "\n",
        "This tutorial designs a network for MNIST-1D classification. MNIST-1D dataset is a simplified version of the famous MNIST dataset but with one-dimensional data. This is useful for understanding and visualizing machine learning concepts in a more tractable setting. See more details about the dataset [here](https://github.com/greydanus/mnist1d).\n",
        "\n",
        "Work through the cells below, running each cell in turn.\n",
        "\n",
        "The code is adapted from https://github.com/udlbook/udlbook/blob/main/Notebooks/Chap11/11_2_Residual_Networks.ipynb\n"
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you're in a Colab to make a local copy of the MNIST 1D repository\n",
        "!git clone https://github.com/greydanus/mnist1d"
      ],
      "metadata": {
        "id": "D5yLObtZCi9J",
        "outputId": "71eb5bac-cfd6-4e8e-a83e-15adea920ec8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mnist1d'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 155 (delta 52), reused 124 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (155/155), 6.48 MiB | 26.11 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist1d\n",
        "import torch.nn.functional as F\n",
        "import random"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5yNLQ1p4Uo3",
        "outputId": "17959c95-8779-41cc-875f-0a9122509acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Inspecting the MNIST-1D Dataset\n",
        "\n",
        "In this section, we are working with the MNIST-1D dataset.\n",
        "\n",
        "### Loading the Dataset\n",
        "- **Retrieve Dataset Arguments:**\n",
        "  - `args = mnist1d.data.get_dataset_args()`: This line gets the default arguments required for loading the MNIST-1D dataset. These arguments could include specifics like batch size, normalization factors, etc.\n",
        "- **Get Dataset:**\n",
        "  - `data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)`: Here, the dataset is loaded with the specified arguments. The parameters include:\n",
        "    - `path='./mnist1d_data.pkl'`: Indicates where the dataset should be loaded from or saved to.\n",
        "    - `download=False`: This specifies that the dataset should not be downloaded if it's not found at the given path.\n",
        "    - `regenerate=False`: Indicates that the dataset should not be regenerated if it already exists.\n",
        "\n",
        "### Dataset Structure\n",
        "- The MNIST-1D dataset contains training and test data, split into inputs (`x` and `x_test`) and outputs (`y` and `y_test`):\n",
        "  - `data['x']`: Training inputs.\n",
        "  - `data['y']`: Training outputs (labels).\n",
        "  - `data['x_test']`: Test inputs.\n",
        "  - `data['y_test']`: Test outputs (labels).\n",
        "\n",
        "### Inspecting the Data\n",
        "- **Training Set Size:**\n",
        "  - `print(\"Examples in training set: {}\".format(len(data['y'])))`: This line prints the number of examples in the training set by checking the length of the training labels.\n",
        "- **Test Set Size:**\n",
        "  - `print(\"Examples in test set: {}\".format(len(data['y_test'])))`: Similarly, this line prints the number of examples in the test set.\n",
        "- **Length of Each Example:**\n",
        "  - `print(\"Length of each example: {}\".format(data['x'].shape[-1]))`: This line prints the length of each example in the dataset. Since the data is one-dimensional, the length refers to the number of features in each example.\n"
      ],
      "metadata": {
        "id": "pbvKFsd38k9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = mnist1d.data.get_dataset_args()\n",
        "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
        "\n",
        "# The training and test input and outputs are in\n",
        "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
        "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
        "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
        "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
      ],
      "metadata": {
        "id": "twI72ZCrCt5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c539174-b5ed-4c91-8fde-8a9a005ac644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from ./mnist1d_data.pkl\n",
            "Examples in training set: 4000\n",
            "Examples in test set: 1000\n",
            "Length of each example: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['x'][:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C16G2rL35Trr",
        "outputId": "955ce7b4-69c5-4d05-d901-a9ea5d8869cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.33200567, -0.47191037, -0.77869708, ..., -0.7167305 ,\n",
              "        -0.96195825, -0.89016639],\n",
              "       [ 1.96548088,  2.30021254,  2.21339278, ..., -1.68751297,\n",
              "        -1.42642212, -1.36421511],\n",
              "       [-0.01930303,  0.07863308,  0.62488909, ..., -1.08555748,\n",
              "        -1.79809121, -2.3153282 ],\n",
              "       ...,\n",
              "       [-1.69449348, -1.2805858 , -0.65125255, ..., -0.72365942,\n",
              "        -0.38266551, -0.03165042],\n",
              "       [ 0.99646721,  0.80844603,  0.1553411 , ..., -0.30286571,\n",
              "        -0.28555128, -0.1183879 ],\n",
              "       [-0.6939948 , -0.27532169,  0.29267968, ..., -1.21624513,\n",
              "        -1.4649417 , -1.65099286]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Load in the data\n",
        "train_data_x = data['x'].transpose()\n",
        "train_data_y = data['y']\n",
        "val_data_x = data['x_test'].transpose()\n",
        "val_data_y = data['y_test']\n",
        "# Print out sizes\n",
        "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
        "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
      ],
      "metadata": {
        "id": "8bKADvLHbiV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2abd5b-454e-4cf4-fc35-46ccfd6a4d13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 4000 examples (columns), each of which has 40 dimensions (rows)\n",
            "Validation data: 1000 examples (columns), each of which has 40 dimensions (rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a Residual Network for MNIST-1D Data\n",
        "\n",
        "In this code snippet, we define a `ResidualNetwork` class, which is a type of neural network model suited for handling the MNIST-1D dataset. This dataset involves 40 input dimensions corresponding to offsets in the MNIST1D template and 10 output dimensions corresponding to the 10 digit classes.\n",
        "\n",
        "### Network Dimensions\n",
        "- `D_i = 40`: Represents the number of input dimensions (40 offsets in the MNIST1D template).\n",
        "- `D_o = 10`: Represents the number of output dimensions (10 digits).\n",
        "\n",
        "### ResidualNetwork Class\n",
        "- **Inheritance:** The `ResidualNetwork` class inherits from `torch.nn.Module`, the base class for all neural network modules in PyTorch.\n",
        "- **Constructor (`__init__`):**\n",
        "  - Parameters:\n",
        "    - `input_size`: The size of the input layer (number of input features).\n",
        "    - `output_size`: The size of the output layer (number of classes).\n",
        "    - `hidden_size=100`: The size of the hidden layers, defaulted to 100.\n",
        "  - Layers:\n",
        "    - `self.linear1`: The first linear layer maps from `input_size` to `hidden_size`.\n",
        "    - `self.linear2` and `self.linear3`: Two additional linear layers, each mapping from `hidden_size` to `hidden_size`.\n",
        "    - `self.linear4`: The final linear layer maps from `hidden_size` to `output_size`.\n",
        "  - `print(\"Initialized MLPBase model with {} parameters\".format(self.count_params()))`: This prints out the total number of parameters in the model, calculated by the `count_params` method.\n",
        "- **count_params Method:**\n",
        "  - Returns the total number of trainable parameters in the model.\n",
        "- **Forward Pass (`forward`):**\n",
        "  - Defines how the input `x` flows through the network.\n",
        "  - `h1 = self.linear1(x)`: First linear transformation.\n",
        "  - `h2 = F.relu(self.linear2(h1))` and `h3 = F.relu(self.linear3(h2))`: Two hidden layers with ReLU activation functions.\n",
        "  - `return self.linear4(h3)`: The output is obtained after the final linear transformation.\n",
        "\n"
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features, out_features)\n",
        "        self.linear2 = nn.Linear(out_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "class ResidualNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size=100, num_blocks=3):\n",
        "        super(ResidualNetwork, self).__init__()\n",
        "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
        "        self.residual_blocks = nn.ModuleList([ResidualBlock(hidden_size, hidden_size) for _ in range(num_blocks)])\n",
        "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
        "        print(\"Initialized ResidualNetwork model with {} parameters\".format(self.count_params()))\n",
        "\n",
        "    def count_params(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear_in(x))\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "        return self.linear_out(x)\n",
        "\n",
        "# Example usage:\n",
        "D_i = 40\n",
        "D_o = 10\n",
        "#resnet_model = ResidualNetwork(input_size=D_i, output_size=D_o)\n"
      ],
      "metadata": {
        "id": "ueLEGrCKYY02"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 40 input dimensions and 10 output dimensions for this data\n",
        "# The inputs correspond to the 40 offsets in the MNIST1D template.\n",
        "D_i = 40\n",
        "# The outputs correspond to the 10 digits\n",
        "D_o = 10\n",
        "\n",
        "class ResidualNetwork(torch.nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size=100):\n",
        "    super(ResidualNetwork, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.linear4 = nn.Linear(hidden_size, output_size)\n",
        "    print(\"Initialized MLPBase model with {} parameters\".format(self.count_params()))\n",
        "\n",
        "  def count_params(self):\n",
        "    return sum([p.view(-1).shape[0] for p in self.parameters()])\n",
        "\n",
        "  # This is not yet a residual network, we need to revise this part in tutorial_1c\n",
        "  def forward(self, x):\n",
        "    h1 = self.linear1(x)\n",
        "    h2 = F.relu(self.linear2(h1))\n",
        "    h3 = F.relu(self.linear3(h2))\n",
        "    return self.linear4(h3)\n"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up the Neural Network for MNIST-1D Classification\n",
        "\n",
        "In this segment, we initialize and configure the neural network model, loss function, optimizer, learning rate scheduler, and data for the MNIST-1D dataset.\n",
        "\n",
        "### Model Initialization\n",
        "- `model = ResidualNetwork(40, 10)`: Creates an instance of the `ResidualNetwork` class with 40 input dimensions and 10 output dimensions. This model will be used for the MNIST-1D digit classification task.\n",
        "\n",
        "### Loss Function\n",
        "- **Cross Entropy Loss:**\n",
        "  - `loss_function = nn.CrossEntropyLoss()`: Defines the loss function as Cross Entropy Loss, which is commonly used for classification tasks. It combines Log Softmax and Negative Log-Likelihood Loss in one single class.\n",
        "\n",
        "### Optimizer\n",
        "- **Stochastic Gradient Descent (SGD):**\n",
        "  - `optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)`: Initializes an SGD optimizer. It updates the model's weights based on the computed gradients.\n",
        "    - `model.parameters()`: Passes the parameters of the model to the optimizer.\n",
        "    - `lr = 0.05`: Sets the learning rate to 0.05.\n",
        "    - `momentum=0.9`: Sets the momentum factor to 0.9, which helps in accelerating the optimizer in the direction of consistent gradients.\n",
        "\n",
        "### Learning Rate Scheduler\n",
        "- **Step Learning Rate Decay:**\n",
        "  - `scheduler = StepLR(optimizer, step_size=20, gamma=0.5)`: Implements a learning rate decay scheduler.\n",
        "    - `step_size=20`: The learning rate is decreased every 20 epochs.\n",
        "    - `gamma=0.5`: The factor by which the learning rate is reduced. Here, it is halved.\n",
        "\n",
        "### Data Preparation\n",
        "- **Converting Data to Torch Tensors:**\n",
        "  - The input data (`train_data_x` and `val_data_x`) and labels (`train_data_y` and `val_data_y`) are converted to PyTorch tensors. This conversion is necessary to utilize PyTorch's efficient tensor operations during training.\n",
        "    - `x_train = torch.tensor(train_data_x.transpose().astype('float32'))`: Transposes and converts the training data to float32 tensors.\n",
        "    - `y_train = torch.tensor(train_data_y.astype('long'))`: Converts the training labels to long tensors.\n",
        "    - `x_val = torch.tensor(val_data_x.transpose().astype('float32'))`: Transposes and converts the validation data to float32 tensors.\n",
        "    - `y_val = torch.tensor(val_data_y.astype('long'))`: Converts the validation labels to long tensors."
      ],
      "metadata": {
        "id": "IrhZeFeyMbT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model\n",
        "model = ResidualNetwork(40, 10)\n",
        "\n",
        "# Choose cross entropy loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# Construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
        "# Object that decreases learning rate by half every 20 epochs\n",
        "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "# Convert data to torch tensors\n",
        "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
        "y_train = torch.tensor(train_data_y.astype('long'))\n",
        "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
        "y_val = torch.tensor(val_data_y.astype('long'))"
      ],
      "metadata": {
        "id": "zE4N3FACMMVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a12c2c-e43c-4bd8-da5a-e58ad2f51e53"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized ResidualNetwork model with 65710 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop for the Neural Network\n",
        "\n",
        "In this section, we define the training loop for our neural network model. This loop iterates over the dataset multiple times (epochs), updating the model's parameters based on the loss computed from the predictions and the actual data.\n",
        "\n",
        "### Data Loader Setup\n",
        "- `data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))`: This line creates a data loader for the training data.\n",
        "  - `TensorDataset(x_train, y_train)`: Wraps tensors into a dataset.\n",
        "  - `batch_size=100`: Each batch will contain 100 samples.\n",
        "  - `shuffle=True`: Shuffles the data every epoch to prevent the model from learning the order of the data.\n",
        "  - `worker_init_fn=np.random.seed(1)`: Ensures reproducibility by setting a seed for the random number generator in each worker.\n",
        "\n",
        "### Model Weight Initialization\n",
        "- `model.apply(weights_init)`: Initializes the model's weights using the `weights_init` function defined earlier.\n",
        "\n",
        "### Training Loop Setup\n",
        "- `n_epoch = 100`: The model will be trained for 100 epochs.\n",
        "- Arrays to store losses and error rates for both training and validation data are initialized.\n",
        "\n",
        "### Epoch Loop\n",
        "- **Outer Loop Over Epochs:**\n",
        "  - `for epoch in range(n_epoch)`: Iterates over the number of epochs.\n",
        "- **Batch Loop:**\n",
        "  - `for i, data in enumerate(data_loader)`: Iterates over each batch in the data loader.\n",
        "  - `x_batch, y_batch = data`: Retrieves inputs and labels for the current batch.\n",
        "  - `optimizer.zero_grad()`: Resets gradient information to zero.\n",
        "  - `pred = model(x_batch)`: Forward pass - computes the predicted outputs.\n",
        "  - `loss = loss_function(pred, y_batch)`: Computes the loss.\n",
        "  - `loss.backward()`: Backward pass - computes the gradients.\n",
        "  - `optimizer.step()`: Performs a single optimization step (parameter update).\n",
        "\n",
        "### Evaluation and Statistics\n",
        "- After each epoch, the model's performance is evaluated on both the training and validation datasets.\n",
        "- The error rate and loss for both training and validation sets are calculated and stored.\n",
        "- The performance metrics for each epoch are printed out.\n",
        "- `scheduler.step()`: Adjusts the learning rate according to the scheduler.\n"
      ],
      "metadata": {
        "id": "vldKM53nNZhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a class that creates the batches\n",
        "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "\n",
        "# Loop over the dataset n_epoch times\n",
        "n_epoch = 100\n",
        "# Store the loss and the % correct at each epoch\n",
        "losses_train = np.zeros((n_epoch))\n",
        "errors_train = np.zeros((n_epoch))\n",
        "losses_val = np.zeros((n_epoch))\n",
        "errors_val = np.zeros((n_epoch))\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # Loop over batches\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # Retrieve inputs and labels for this batch\n",
        "    x_batch, y_batch = data\n",
        "    # Zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass -- calculate model output\n",
        "    pred = model(x_batch)\n",
        "    # Compute the loss\n",
        "    loss = loss_function(pred, y_batch)\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # SGD update\n",
        "    optimizer.step()\n",
        "\n",
        "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
        "  pred_train = model(x_train)\n",
        "  pred_val = model(x_val)\n",
        "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
        "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
        "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
        "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
        "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
        "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
        "\n",
        "  # Tell scheduler to consider updating learning rate\n",
        "  scheduler.step()"
      ],
      "metadata": {
        "id": "NYw8I_3mmX5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b602a1a-74c2-409b-8944-5a8c3cd45dea"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     0, train loss 1.732187, train error 70.28,  val loss 1.758264, percent error 72.00\n",
            "Epoch     1, train loss 1.598942, train error 65.03,  val loss 1.646047, percent error 67.50\n",
            "Epoch     2, train loss 1.473980, train error 59.25,  val loss 1.519214, percent error 64.30\n",
            "Epoch     3, train loss 1.246361, train error 49.90,  val loss 1.350332, percent error 55.30\n",
            "Epoch     4, train loss 1.161279, train error 45.60,  val loss 1.284395, percent error 52.00\n",
            "Epoch     5, train loss 1.178181, train error 46.72,  val loss 1.380627, percent error 54.80\n",
            "Epoch     6, train loss 0.960919, train error 37.28,  val loss 1.234987, percent error 49.40\n",
            "Epoch     7, train loss 0.895267, train error 35.07,  val loss 1.225174, percent error 47.60\n",
            "Epoch     8, train loss 0.803277, train error 31.55,  val loss 1.143896, percent error 44.70\n",
            "Epoch     9, train loss 0.725611, train error 27.93,  val loss 1.162935, percent error 45.10\n",
            "Epoch    10, train loss 0.718211, train error 28.15,  val loss 1.171820, percent error 43.40\n",
            "Epoch    11, train loss 0.669410, train error 25.15,  val loss 1.233362, percent error 45.10\n",
            "Epoch    12, train loss 0.624162, train error 24.12,  val loss 1.205979, percent error 43.60\n",
            "Epoch    13, train loss 0.555623, train error 20.88,  val loss 1.177172, percent error 38.70\n",
            "Epoch    14, train loss 0.589184, train error 22.15,  val loss 1.143071, percent error 39.90\n",
            "Epoch    15, train loss 0.551265, train error 21.05,  val loss 1.217799, percent error 40.80\n",
            "Epoch    16, train loss 0.408882, train error 15.00,  val loss 1.093065, percent error 37.00\n",
            "Epoch    17, train loss 0.349302, train error 12.32,  val loss 1.102609, percent error 36.00\n",
            "Epoch    18, train loss 0.342409, train error 12.68,  val loss 1.101047, percent error 35.60\n",
            "Epoch    19, train loss 0.374261, train error 13.38,  val loss 1.270294, percent error 39.00\n",
            "Epoch    20, train loss 0.164805, train error 4.88,  val loss 1.183602, percent error 35.90\n",
            "Epoch    21, train loss 0.114213, train error 3.05,  val loss 1.266282, percent error 34.50\n",
            "Epoch    22, train loss 0.076434, train error 1.80,  val loss 1.443972, percent error 35.00\n",
            "Epoch    23, train loss 0.050416, train error 0.93,  val loss 1.544277, percent error 35.00\n",
            "Epoch    24, train loss 0.030253, train error 0.45,  val loss 1.696281, percent error 35.30\n",
            "Epoch    25, train loss 0.020090, train error 0.07,  val loss 1.809907, percent error 35.40\n",
            "Epoch    26, train loss 0.015236, train error 0.10,  val loss 1.889409, percent error 35.10\n",
            "Epoch    27, train loss 0.008748, train error 0.00,  val loss 1.980613, percent error 35.60\n",
            "Epoch    28, train loss 0.005601, train error 0.00,  val loss 2.050347, percent error 35.10\n",
            "Epoch    29, train loss 0.004183, train error 0.00,  val loss 2.131462, percent error 34.70\n",
            "Epoch    30, train loss 0.003342, train error 0.00,  val loss 2.189772, percent error 34.40\n",
            "Epoch    31, train loss 0.002869, train error 0.00,  val loss 2.240210, percent error 34.70\n",
            "Epoch    32, train loss 0.002467, train error 0.00,  val loss 2.283718, percent error 34.80\n",
            "Epoch    33, train loss 0.002202, train error 0.00,  val loss 2.319711, percent error 34.50\n",
            "Epoch    34, train loss 0.001959, train error 0.00,  val loss 2.350649, percent error 34.80\n",
            "Epoch    35, train loss 0.001770, train error 0.00,  val loss 2.391077, percent error 34.70\n",
            "Epoch    36, train loss 0.001607, train error 0.00,  val loss 2.415784, percent error 34.80\n",
            "Epoch    37, train loss 0.001472, train error 0.00,  val loss 2.445340, percent error 34.60\n",
            "Epoch    38, train loss 0.001373, train error 0.00,  val loss 2.472074, percent error 34.70\n",
            "Epoch    39, train loss 0.001260, train error 0.00,  val loss 2.495777, percent error 34.80\n",
            "Epoch    40, train loss 0.001213, train error 0.00,  val loss 2.507752, percent error 34.90\n",
            "Epoch    41, train loss 0.001171, train error 0.00,  val loss 2.520318, percent error 34.80\n",
            "Epoch    42, train loss 0.001131, train error 0.00,  val loss 2.530915, percent error 35.00\n",
            "Epoch    43, train loss 0.001095, train error 0.00,  val loss 2.543597, percent error 35.10\n",
            "Epoch    44, train loss 0.001061, train error 0.00,  val loss 2.554080, percent error 35.00\n",
            "Epoch    45, train loss 0.001028, train error 0.00,  val loss 2.563939, percent error 35.30\n",
            "Epoch    46, train loss 0.000998, train error 0.00,  val loss 2.574188, percent error 35.30\n",
            "Epoch    47, train loss 0.000969, train error 0.00,  val loss 2.583156, percent error 35.20\n",
            "Epoch    48, train loss 0.000943, train error 0.00,  val loss 2.592964, percent error 35.10\n",
            "Epoch    49, train loss 0.000915, train error 0.00,  val loss 2.602024, percent error 35.20\n",
            "Epoch    50, train loss 0.000891, train error 0.00,  val loss 2.612278, percent error 35.30\n",
            "Epoch    51, train loss 0.000867, train error 0.00,  val loss 2.619262, percent error 35.10\n",
            "Epoch    52, train loss 0.000844, train error 0.00,  val loss 2.628832, percent error 35.10\n",
            "Epoch    53, train loss 0.000823, train error 0.00,  val loss 2.638269, percent error 35.30\n",
            "Epoch    54, train loss 0.000802, train error 0.00,  val loss 2.645206, percent error 35.10\n",
            "Epoch    55, train loss 0.000783, train error 0.00,  val loss 2.656030, percent error 35.20\n",
            "Epoch    56, train loss 0.000764, train error 0.00,  val loss 2.662344, percent error 35.10\n",
            "Epoch    57, train loss 0.000746, train error 0.00,  val loss 2.670977, percent error 35.20\n",
            "Epoch    58, train loss 0.000728, train error 0.00,  val loss 2.678092, percent error 35.20\n",
            "Epoch    59, train loss 0.000712, train error 0.00,  val loss 2.686080, percent error 35.20\n",
            "Epoch    60, train loss 0.000704, train error 0.00,  val loss 2.689330, percent error 35.20\n",
            "Epoch    61, train loss 0.000696, train error 0.00,  val loss 2.693243, percent error 35.20\n",
            "Epoch    62, train loss 0.000688, train error 0.00,  val loss 2.697141, percent error 35.20\n",
            "Epoch    63, train loss 0.000681, train error 0.00,  val loss 2.700417, percent error 35.20\n",
            "Epoch    64, train loss 0.000673, train error 0.00,  val loss 2.704285, percent error 35.30\n",
            "Epoch    65, train loss 0.000666, train error 0.00,  val loss 2.707681, percent error 35.20\n",
            "Epoch    66, train loss 0.000659, train error 0.00,  val loss 2.711339, percent error 35.20\n",
            "Epoch    67, train loss 0.000652, train error 0.00,  val loss 2.715082, percent error 35.30\n",
            "Epoch    68, train loss 0.000645, train error 0.00,  val loss 2.718793, percent error 35.30\n",
            "Epoch    69, train loss 0.000639, train error 0.00,  val loss 2.721559, percent error 35.30\n",
            "Epoch    70, train loss 0.000632, train error 0.00,  val loss 2.725429, percent error 35.30\n",
            "Epoch    71, train loss 0.000626, train error 0.00,  val loss 2.728684, percent error 35.30\n",
            "Epoch    72, train loss 0.000619, train error 0.00,  val loss 2.731808, percent error 35.40\n",
            "Epoch    73, train loss 0.000613, train error 0.00,  val loss 2.734937, percent error 35.30\n",
            "Epoch    74, train loss 0.000607, train error 0.00,  val loss 2.738484, percent error 35.30\n",
            "Epoch    75, train loss 0.000601, train error 0.00,  val loss 2.742287, percent error 35.30\n",
            "Epoch    76, train loss 0.000595, train error 0.00,  val loss 2.744837, percent error 35.40\n",
            "Epoch    77, train loss 0.000589, train error 0.00,  val loss 2.747949, percent error 35.40\n",
            "Epoch    78, train loss 0.000584, train error 0.00,  val loss 2.751837, percent error 35.30\n",
            "Epoch    79, train loss 0.000578, train error 0.00,  val loss 2.754570, percent error 35.30\n",
            "Epoch    80, train loss 0.000575, train error 0.00,  val loss 2.756291, percent error 35.30\n",
            "Epoch    81, train loss 0.000572, train error 0.00,  val loss 2.757737, percent error 35.30\n",
            "Epoch    82, train loss 0.000570, train error 0.00,  val loss 2.759438, percent error 35.30\n",
            "Epoch    83, train loss 0.000567, train error 0.00,  val loss 2.761120, percent error 35.30\n",
            "Epoch    84, train loss 0.000564, train error 0.00,  val loss 2.762655, percent error 35.30\n",
            "Epoch    85, train loss 0.000562, train error 0.00,  val loss 2.764086, percent error 35.20\n",
            "Epoch    86, train loss 0.000559, train error 0.00,  val loss 2.765788, percent error 35.30\n",
            "Epoch    87, train loss 0.000557, train error 0.00,  val loss 2.767262, percent error 35.30\n",
            "Epoch    88, train loss 0.000554, train error 0.00,  val loss 2.768900, percent error 35.20\n",
            "Epoch    89, train loss 0.000552, train error 0.00,  val loss 2.770308, percent error 35.20\n",
            "Epoch    90, train loss 0.000549, train error 0.00,  val loss 2.771863, percent error 35.20\n",
            "Epoch    91, train loss 0.000546, train error 0.00,  val loss 2.773502, percent error 35.20\n",
            "Epoch    92, train loss 0.000544, train error 0.00,  val loss 2.775108, percent error 35.20\n",
            "Epoch    93, train loss 0.000541, train error 0.00,  val loss 2.776420, percent error 35.20\n",
            "Epoch    94, train loss 0.000539, train error 0.00,  val loss 2.777903, percent error 35.20\n",
            "Epoch    95, train loss 0.000537, train error 0.00,  val loss 2.779552, percent error 35.10\n",
            "Epoch    96, train loss 0.000534, train error 0.00,  val loss 2.780860, percent error 35.10\n",
            "Epoch    97, train loss 0.000532, train error 0.00,  val loss 2.782508, percent error 35.20\n",
            "Epoch    98, train loss 0.000529, train error 0.00,  val loss 2.783889, percent error 35.20\n",
            "Epoch    99, train loss 0.000527, train error 0.00,  val loss 2.785424, percent error 35.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_train,'r-',label='train')\n",
        "ax.plot(errors_val,'b-',label='test')\n",
        "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
        "ax.set_title('TrainError %3.2f, Val Error %3.2f'%(errors_train[-1],errors_val[-1]))\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CcP_VyEmE2sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "21eabf38-0253-473c-9077-5609de430a95"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ire"
      ],
      "metadata": {
        "id": "4Y7e6Y2sPSym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqdTsKI1PSBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's Next?\n",
        "\n",
        "The primary motivation of residual networks is to allow training of much deeper networks. Change the network structure to become a residual network.\n",
        "\n",
        "TODO: Try running this network with and without the residual connections.  Does adding the residual connections change the performance?"
      ],
      "metadata": {
        "id": "wMmqhmxuAx0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#draft ↓"
      ],
      "metadata": {
        "id": "hQvu5jmkRTl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([i for i in range(30)])\n",
        "x.shape, x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hhT2IwYRTDL",
        "outputId": "93fe319e-fd8f-4b04-9df8-9fe253412800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30,),\n",
              " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.reshape(30, 1)\n",
        "y.shape, y"
      ],
      "metadata": {
        "id": "a_AXhFDWR--4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.array([1,2,4,5,6])\n",
        "n.reshape\n",
        "n"
      ],
      "metadata": {
        "id": "FxVkoRM8TZpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "103bd269-ff10-4778-bd75-ad0ce46a7198"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a5fd8959bb01>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hnyLIPUT9w2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}